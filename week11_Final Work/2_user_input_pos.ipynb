{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实现用户输入，进行POS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入相应的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding='UTF-8'\n",
    "###\n",
    "# 将训练好的词性标注模型封装为服务\n",
    "###\n",
    "# 加载存储的模型开始预测\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将文本中的词语转换为索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 由于将词语转化为索引的word_index需要与词向量模型对齐，故在导入词向量模型后再将X进行处理\n",
    "def tokenizer(texts, word_index):\n",
    "    data = []\n",
    "    MAX_SEQUENCE_LENGTH = 100\n",
    "    for sentence in texts:\n",
    "        new_sentence = []\n",
    "        for word in sentence:\n",
    "            try:\n",
    "                new_sentence.append(word_index[word])  # 把文本中的词语转化为index\n",
    "            except:\n",
    "                new_sentence.append(0)\n",
    "            \n",
    "        data.append(new_sentence)\n",
    "    # 使用kears的内置函数padding对齐句子,好处是输出numpy数组，不用自己转化了\n",
    "    data = sequence.pad_sequences(data, maxlen = MAX_SEQUENCE_LENGTH, padding='post', truncating='post')\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入{索引：词语}字典对输入文本进行处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_input(input_text_segged):\n",
    "    # 序号化 文本，tokenizer句子，并返回每个句子所对应的词语索引，并填充句子长度至100\n",
    "    # 因为只有一句，所以在该输入句外加上了括号\n",
    "    text_dictionary = np.load('./word_index.npy', allow_pickle=True).item()   # 导入{索引：词语}字典\n",
    "    padded_input_text_indexs = tokenizer([input_text_segged], text_dictionary) \n",
    "    \n",
    "    return padded_input_text_indexs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将输出转化为标签格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_output(output):\n",
    "    # 导入{标签：索引}字典\n",
    "    label_dictionary = np.load('./labels_index.npy', allow_pickle=True).item()\n",
    "    # 将{标签：索引}字典label_dictionary转换为{索引：标签}字典label_dictionary_index_label\n",
    "    label_dictionary_index_label = {label_dictionary[key]:key for key in label_dictionary}\n",
    "    \n",
    "    # 将预测的每一个标签对应向量转化为索引号\n",
    "    output_index = []\n",
    "    for label_vector in output[0]:\n",
    "        label_max_prob = max(label_vector.tolist())                        # 先转换为列表格式，再找出最大值\n",
    "        label_max_prob_index = label_vector.tolist().index(label_max_prob) # 利用列表找到最大值对应的索引\n",
    "        output_index.append(label_max_prob_index)\n",
    "    processed_output = [label_dictionary_index_label[index] for index in output_index]\n",
    "\n",
    "    return processed_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将输入的文本进行分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_text_seg(text_to_be_seg):\n",
    "    # 将输入的文本进行分词处理\n",
    "    print(\">>> Processing input text...\")\n",
    "    segged_text = jieba.cut(text_to_be_tag, cut_all=False)\n",
    "    segged_text = '/'.join(segged_text)\n",
    "    segged_text = segged_text.split('/')\n",
    "    print('>>> Segged text：\\n', segged_text)\n",
    "\n",
    "    return segged_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对输入的文本的词性进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_text_predict(segged_text):\n",
    "    # 将分词后的输入文本对应模型训练时所用的词典，转化为index\n",
    "    processed_input = transfer_input(segged_text)\n",
    "    \n",
    "    # 利用模型进行预测\n",
    "    print(\">>> Using loaded model to predict...\")\n",
    "    output = pos_model.predict(processed_input)\n",
    "    \n",
    "    # 将输出转化为标签格式\n",
    "    processed_output = transfer_output(output)\n",
    "    \n",
    "    # 将原词和词性组合输出\n",
    "    final_output = []\n",
    "    for index in range(len(segged_text)):\n",
    "        final_output.append({segged_text[index]:processed_output[index]})\n",
    "\n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取用户输入，加载模型进行预测，输出预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = =  Loading model... = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "\n",
      "Model loaded successfully!\n",
      "\n",
      " = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =   POS start  = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "\n",
      ">>> Please input your sentence(if you want to quit, just type in quit):\n",
      "随着科技、经济、社会之间关系的日益密切，以及支持个人、组织、国家竞争的信息需求之日益迫切，信息分析突破了科技信息分析的范围，形成了众多分支领域，成为现代信息咨询业的重要组成部分。\n",
      "\n",
      " -*-*-*-*-*-*-*-*-*-*-*-*-*-*-*  Sentence processing  -*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      ">>> Processing input text...\n",
      ">>> Segged text：\n",
      " ['随着', '科技', '、', '经济', '、', '社会', '之间', '关系', '的', '日益', '密切', '，', '以及', '支持', '个人', '、', '组织', '、', '国家', '竞争', '的', '信息', '需求', '之', '日益', '迫切', '，', '信息', '分析', '突破', '了', '科技', '信息', '分析', '的', '范围', '，', '形成', '了', '众多', '分支', '领域', '，', '成为', '现代', '信息', '咨询业', '的', '重要', '组成部分', '。']\n",
      "\n",
      " -*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*  POS output  -*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      ">>> Using loaded model to predict...\n",
      "[{'随着': 'P'}, {'科技': 'NN'}, {'、': 'PU'}, {'经济': 'NN'}, {'、': 'PU'}, {'社会': 'NN'}, {'之间': 'LC'}, {'关系': 'NN'}, {'的': 'DEG'}, {'日益': 'NN'}, {'密切': 'VA'}, {'，': 'PU'}, {'以及': 'CC'}, {'支持': 'VV'}, {'个人': 'NN'}, {'、': 'PU'}, {'组织': 'NN'}, {'、': 'PU'}, {'国家': 'NN'}, {'竞争': 'NN'}, {'的': 'DEC'}, {'信息': 'NN'}, {'需求': 'NN'}, {'之': 'DEG'}, {'日益': 'NN'}, {'迫切': 'NN'}, {'，': 'PU'}, {'信息': 'NN'}, {'分析': 'NN'}, {'突破': 'VV'}, {'了': 'AS'}, {'科技': 'NN'}, {'信息': 'NN'}, {'分析': 'NN'}, {'的': 'DEC'}, {'范围': 'NN'}, {'，': 'PU'}, {'形成': 'VV'}, {'了': 'AS'}, {'众多': 'CD'}, {'分支': 'NN'}, {'领域': 'NN'}, {'，': 'PU'}, {'成为': 'VV'}, {'现代': 'JJ'}, {'信息': 'NN'}, {'咨询业': 'NN'}, {'的': 'DEG'}, {'重要': 'JJ'}, {'组成部分': 'NN'}, {'。': 'PU'}] \n",
      "\n",
      "\n",
      " = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =   POS start  = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "\n",
      ">>> Please input your sentence(if you want to quit, just type in quit):\n",
      "美国防政策委员会几位知名度较高的成员于当地时间26日被特朗普政府撤职。美媒称，这是特朗普政府对长期的外交政策专家和国家安全机构人士的又一次“清洗”。\n",
      "\n",
      " -*-*-*-*-*-*-*-*-*-*-*-*-*-*-*  Sentence processing  -*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      ">>> Processing input text...\n",
      ">>> Segged text：\n",
      " ['美国防', '政策', '委员会', '几位', '知名度', '较', '高', '的', '成员', '于', '当地', '时间', '26', '日', '被', '特朗普', '政府', '撤职', '。', '美媒称', '，', '这是', '特朗普', '政府', '对', '长期', '的', '外交政策', '专家', '和', '国家', '安全', '机构', '人士', '的', '又', '一次', '“', '清洗', '”', '。']\n",
      "\n",
      " -*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*  POS output  -*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      ">>> Using loaded model to predict...\n",
      "[{'美国防': 'PU'}, {'政策': 'NN'}, {'委员会': 'NN'}, {'几位': 'NN'}, {'知名度': 'NN'}, {'较': 'AD'}, {'高': 'VA'}, {'的': 'DEC'}, {'成员': 'NN'}, {'于': 'P'}, {'当地': 'NN'}, {'时间': 'NN'}, {'26': 'CD'}, {'日': 'M'}, {'被': 'LB'}, {'特朗普': 'NR'}, {'政府': 'NN'}, {'撤职': 'VV'}, {'。': 'PU'}, {'美媒称': 'PU'}, {'，': 'PU'}, {'这是': 'PU'}, {'特朗普': 'NR'}, {'政府': 'NN'}, {'对': 'P'}, {'长期': 'NN'}, {'的': 'DEG'}, {'外交政策': 'NN'}, {'专家': 'NN'}, {'和': 'CC'}, {'国家': 'NN'}, {'安全': 'NN'}, {'机构': 'NN'}, {'人士': 'NN'}, {'的': 'DEG'}, {'又': 'AD'}, {'一次': 'NN'}, {'“': 'PU'}, {'清洗': 'VV'}, {'”': 'PU'}, {'。': 'PU'}] \n",
      "\n",
      "\n",
      " = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =   POS start  = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "\n",
      ">>> Please input your sentence(if you want to quit, just type in quit):\n",
      "运动和健康，会成为中国人越来越关注的话题，而其背后所隐藏的巨大商业价值，也正逐渐浮出水面。其中作为运动的“伴侣”，智能可穿戴设备在中国正处在一个关键拐点——向上满足高端运动发烧友，向下满足大众运动需求。而这是两个完全不同的挑战。现在的智能运动设备的高弃用率，表明大众的需求没能被很好满足。\n",
      "\n",
      " -*-*-*-*-*-*-*-*-*-*-*-*-*-*-*  Sentence processing  -*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      ">>> Processing input text...\n",
      ">>> Segged text：\n",
      " ['运动', '和', '健康', '，', '会', '成为', '中国', '人', '越来越', '关注', '的', '话题', '，', '而', '其', '背后', '所', '隐藏', '的', '巨大', '商业价值', '，', '也', '正', '逐渐', '浮出', '水面', '。', '其中', '作为', '运动', '的', '“', '伴侣', '”', '，', '智能', '可', '穿戴', '设备', '在', '中国', '正', '处在', '一个', '关键', '拐点', '—', '—', '向上', '满足', '高端', '运动', '发烧友', '，', '向下', '满足', '大众', '运动', '需求', '。', '而', '这', '是', '两个', '完全', '不同', '的', '挑战', '。', '现在', '的', '智能', '运动', '设备', '的', '高弃', '用率', '，', '表明', '大众', '的', '需求', '没能', '被', '很', '好', '满足', '。']\n",
      "\n",
      " -*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*  POS output  -*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      ">>> Using loaded model to predict...\n",
      "[{'运动': 'NN'}, {'和': 'CC'}, {'健康': 'NN'}, {'，': 'PU'}, {'会': 'VV'}, {'成为': 'VV'}, {'中国': 'NR'}, {'人': 'NN'}, {'越来越': 'AD'}, {'关注': 'VV'}, {'的': 'DEC'}, {'话题': 'NN'}, {'，': 'PU'}, {'而': 'AD'}, {'其': 'PN'}, {'背后': 'NN'}, {'所': 'MSP'}, {'隐藏': 'VV'}, {'的': 'DEC'}, {'巨大': 'JJ'}, {'商业价值': 'NN'}, {'，': 'PU'}, {'也': 'AD'}, {'正': 'AD'}, {'逐渐': 'AD'}, {'浮出': 'VV'}, {'水面': 'NN'}, {'。': 'PU'}, {'其中': 'NN'}, {'作为': 'VV'}, {'运动': 'NN'}, {'的': 'DEC'}, {'“': 'PU'}, {'伴侣': 'NN'}, {'”': 'PU'}, {'，': 'PU'}, {'智能': 'NN'}, {'可': 'VV'}, {'穿戴': 'VV'}, {'设备': 'NN'}, {'在': 'P'}, {'中国': 'NR'}, {'正': 'AD'}, {'处在': 'VV'}, {'一个': 'NN'}, {'关键': 'JJ'}, {'拐点': 'NN'}, {'—': 'PU'}, {'—': 'PU'}, {'向上': 'AD'}, {'满足': 'VV'}, {'高端': 'NN'}, {'运动': 'NN'}, {'发烧友': 'NN'}, {'，': 'PU'}, {'向下': 'AD'}, {'满足': 'VV'}, {'大众': 'NN'}, {'运动': 'NN'}, {'需求': 'NN'}, {'。': 'PU'}, {'而': 'MSP'}, {'这': 'PN'}, {'是': 'VC'}, {'两个': 'NN'}, {'完全': 'AD'}, {'不同': 'VA'}, {'的': 'DEC'}, {'挑战': 'NN'}, {'。': 'PU'}, {'现在': 'NT'}, {'的': 'DEG'}, {'智能': 'NN'}, {'运动': 'NN'}, {'设备': 'NN'}, {'的': 'DEG'}, {'高弃': 'NN'}, {'用率': 'NN'}, {'，': 'PU'}, {'表明': 'VV'}, {'大众': 'NN'}, {'的': 'DEG'}, {'需求': 'NN'}, {'没能': 'AD'}, {'被': 'SB'}, {'很': 'AD'}, {'好': 'VA'}, {'满足': 'NN'}, {'。': 'PU'}] \n",
      "\n",
      "\n",
      " = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =   POS start  = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "\n",
      ">>> Please input your sentence(if you want to quit, just type in quit):\n",
      "quit\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # 导入训练好的词性标注深度学习模型\n",
    "    print(\"= \"*30 + \" Loading model... \" + \"= \"*30)\n",
    "    pos_model = load_model(\"./cn_pos_tag_BiGRU.h5\")\n",
    "    print(\"\\nModel loaded successfully!\")\n",
    "    \n",
    "    while True:\n",
    "        # 接收输入文本\n",
    "        print('\\n', '= '*31, ' POS start ', '= '*31)\n",
    "        text_to_be_tag = input(\"\\n>>> Please input your sentence(if you want to quit, just type in quit):\\n\")\n",
    "        \n",
    "        # 用户如果输入'quit'，则退出程序\n",
    "        if text_to_be_tag == 'quit':\n",
    "            break\n",
    "            \n",
    "        # 处理输入的文本，进行分词\n",
    "        print('\\n', '-*'*15, ' Sentence processing ', '-*'*15)\n",
    "        segged_text = pos_text_seg(text_to_be_tag)\n",
    "        \n",
    "        # 输出预测结果\n",
    "        print('\\n', '-*'*17, ' POS output ', '-*'*17)\n",
    "        final_output = pos_text_predict(segged_text)       \n",
    "        print(final_output, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
