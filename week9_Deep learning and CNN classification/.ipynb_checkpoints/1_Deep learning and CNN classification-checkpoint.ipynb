{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 深度学习与卷积网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集：mnist\n",
    "MNIST数据集是机器学习领域中非常经典的一个数据集，由60000个训练样本和10000个测试样本组成，每个样本都是一张28 * 28像素的灰度手写数字图片。\n",
    "\n",
    "灰度图：Gray Scale Image 或是Grey Scale Image，又称灰阶图。把白色与黑色之间按对数关系分为若干等级，称为灰度。灰度分为256阶。\n",
    "\n",
    "任何颜色都有红、绿、蓝三原色组成，而灰度图只有一个通道，他有256个灰度等级，255代表全白，0表示全黑。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. 导入工具库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import keras\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集的shape为： (60000, 28, 28)\n",
      "训练集的元素个数X_train.shape[0]为： 60000\n"
     ]
    }
   ],
   "source": [
    "print('训练集的shape为：', X_train.shape)\n",
    "print('训练集的元素个数X_train.shape[0]为：', X_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集的第一个元素为：\n",
      " [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print('训练集的第一个元素为：\\n', X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对数据进行处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置图像的行列大小\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# reshape为60000个（X_train.shape[0]）28*28的矩阵\n",
    "# 并添加最后一位1表示一维空间（彩色是在处理的时候是三维空间RGB，用3表示）\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "# 改变数据精度（提高计算效率）\n",
    "X_train = X_train.astype(\"float32\")\n",
    "X_test = X_test.astype(\"float32\")\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "## 把数字转成one-hot的形式\n",
    "# 设置标签类别总数，大于max(y)（标签从0开始的）\n",
    "num_category = 10\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_category)\n",
    "y_test = keras.utils.to_categorical(y_test, num_category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 拆分训练数据集，构建对训练过程进行监控的验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 对训练集进行再拆分，拆分出验证集\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x19a41a07978>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 展示第一个的图像\n",
    "plt.imshow(X_train[0].reshape(28, 28))\n",
    "\n",
    "# 由于在拆分数据集时会打乱顺序，所以输出的不是原始位置的数字"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 数据增强\n",
    "为了提高模型的泛化能力，我们使用到了一个叫做`数据增强`的处理，在keras中可以通过ImageDataGenerator完成，详细的可以参见[Image Data Generator](http://keras.io/preprocessing/image/)。这个处理会对输入的图片数据进行例如旋转、平移、截取、水平、垂直翻转等处理，并不改变图像内容，但是能扩量计算机没有看过的数据，提高模型的泛化能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tip: 这部分计算量会比较大，未纳入本次实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "generated_images = ImageDataGenerator(featurewise_center=True, # set input mean to 0 over the dataset\n",
    "                                      samplewise_center=False,\n",
    "                                      featurewise_std_normalization=True,\n",
    "                                      samplewise_std_normalization=False,\n",
    "                                      zca_whitening=False,\n",
    "                                      rotation_range=0,\n",
    "                                      width_shift_range=0.2,\n",
    "                                      height_shift_range=0.2,\n",
    "                                      horizontal_flip=True,\n",
    "                                      vertical_flip=False\n",
    "                                     )\n",
    "\n",
    "generated_images.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epoch = 10 # 迭代轮次\n",
    "batch_size = 128 # 一个batch的数据量\n",
    "nb_filters = 32 # 卷积层filter的个数\n",
    "nb_pool = 2 # 池化层的kernal size\n",
    "nb_conv = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建模型\n",
    "model = Sequential()\n",
    "\n",
    "# 加入卷积层\n",
    "model.add(Conv2D(nb_filters, \n",
    "                 (nb_conv, nb_conv), \n",
    "                 padding='same', \n",
    "                 input_shape=(28, 28, 1),\n",
    "                 activation='relu'\n",
    "                )\n",
    "         )\n",
    "# 加入最大池化层\n",
    "model.add(MaxPool2D(2, 2))\n",
    "\n",
    "# 加入卷积层\n",
    "model.add(Conv2D(nb_filters, \n",
    "                 (nb_conv, nb_conv), \n",
    "                 activation='relu'\n",
    "                )\n",
    "         )\n",
    "# 加入最大池化层\n",
    "model.add(MaxPool2D(2, 2))\n",
    "\n",
    "# 加入卷积层\n",
    "model.add(Conv2D(nb_filters, \n",
    "                 (nb_conv, nb_conv), \n",
    "                 activation='relu'\n",
    "                )\n",
    "         )\n",
    "# 加入最大池化层\n",
    "model.add(MaxPool2D(2, 2))\n",
    "\n",
    "# 将二维输出转换为一维\n",
    "model.add(Flatten())\n",
    "\n",
    "# 添加全连接层\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy']\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 12, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 36,618\n",
      "Trainable params: 36,618\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 模型训练与评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集标签的shape为： (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print('测试集标签的shape为：', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "352/352 [==============================] - 32s 90ms/step - loss: 0.5150 - accuracy: 0.8341 - val_loss: 0.1125 - val_accuracy: 0.9645\n",
      "Epoch 2/10\n",
      "352/352 [==============================] - 32s 92ms/step - loss: 0.1425 - accuracy: 0.9575 - val_loss: 0.0841 - val_accuracy: 0.9739\n",
      "Epoch 3/10\n",
      "352/352 [==============================] - 32s 91ms/step - loss: 0.1003 - accuracy: 0.9701 - val_loss: 0.0637 - val_accuracy: 0.9787\n",
      "Epoch 4/10\n",
      "352/352 [==============================] - 32s 90ms/step - loss: 0.0802 - accuracy: 0.9758 - val_loss: 0.0588 - val_accuracy: 0.9819\n",
      "Epoch 5/10\n",
      "352/352 [==============================] - 32s 92ms/step - loss: 0.0664 - accuracy: 0.9795 - val_loss: 0.0523 - val_accuracy: 0.9843\n",
      "Epoch 6/10\n",
      "352/352 [==============================] - 32s 90ms/step - loss: 0.0586 - accuracy: 0.9825 - val_loss: 0.0591 - val_accuracy: 0.9812\n",
      "Epoch 7/10\n",
      "352/352 [==============================] - 31s 89ms/step - loss: 0.0519 - accuracy: 0.9839 - val_loss: 0.0434 - val_accuracy: 0.9870\n",
      "Epoch 8/10\n",
      "352/352 [==============================] - 32s 90ms/step - loss: 0.0468 - accuracy: 0.9855 - val_loss: 0.0416 - val_accuracy: 0.9877\n",
      "Epoch 9/10\n",
      "352/352 [==============================] - 32s 90ms/step - loss: 0.0422 - accuracy: 0.9866 - val_loss: 0.0404 - val_accuracy: 0.9890\n",
      "Epoch 10/10\n",
      "352/352 [==============================] - 31s 89ms/step - loss: 0.0370 - accuracy: 0.9886 - val_loss: 0.0396 - val_accuracy: 0.9883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19a42917d30>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, \n",
    "          y_train,\n",
    "          epochs = nb_epoch,\n",
    "          batch_size = batch_size,\n",
    "          verbose = 1, # 展示训练过程\n",
    "          validation_data = (X_val, y_val) # 验证集数据\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0184 - accuracy: 0.9940\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.018396474421024323, 0.9940444231033325]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练集评估\n",
    "model.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0312 - accuracy: 0.9902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03122025728225708, 0.9901999831199646]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试评估\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 扩展研究\n",
    "学有余力的同学可以尝试采用keras自带的cifar10数据集进一步开展实验。了解图像的RGB表达模式（对比本实验中的灰度图模式）。\n",
    "\n",
    "CIFAR-10 是一个包含60000张图片的数据集。其中每张照片为32*32的彩色照片，每个像素点包括RGB三个数值，数值范围 0 ~ 255。所有照片分属10个不同的类别，分别是 'airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'。其中五万张图片被划分为训练集，剩下的一万张图片属于测试集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
